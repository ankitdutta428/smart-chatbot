{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5253,"sourceType":"modelInstanceVersion","modelInstanceId":4038,"modelId":2195},{"sourceId":33551,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":28083,"modelId":39106}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:17:45.951893Z","iopub.execute_input":"2025-01-08T21:17:45.952192Z","iopub.status.idle":"2025-01-08T21:17:46.246497Z","shell.execute_reply.started":"2025-01-08T21:17:45.952167Z","shell.execute_reply":"2025-01-08T21:17:46.245814Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q -U trl\n!pip install -q -U peft\n!pip install -q -U transformers\n!pip install -q -U accelerate\n!pip install huggingface-hub\n!pip install -q -U torch --index-url https://download.pytorch.org/whl/cu117\n!pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n!pip install -q -U datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:17:47.673965Z","iopub.execute_input":"2025-01-08T21:17:47.674392Z","iopub.status.idle":"2025-01-08T21:18:29.643507Z","shell.execute_reply.started":"2025-01-08T21:17:47.674366Z","shell.execute_reply":"2025-01-08T21:18:29.642341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch \nfrom trl import SFTTrainer\nfrom peft import LoraConfig\nfrom datasets import Dataset\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, TrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:18:29.650777Z","iopub.execute_input":"2025-01-08T21:18:29.651118Z","iopub.status.idle":"2025-01-08T21:18:45.628436Z","shell.execute_reply.started":"2025-01-08T21:18:29.651071Z","shell.execute_reply":"2025-01-08T21:18:45.627546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\ndataset_path = \"bitext/Bitext-telco-llm-chatbot-training-dataset\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:18:48.744280Z","iopub.execute_input":"2025-01-08T21:18:48.744540Z","iopub.status.idle":"2025-01-08T21:18:48.748232Z","shell.execute_reply.started":"2025-01-08T21:18:48.744521Z","shell.execute_reply":"2025-01-08T21:18:48.747415Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"compute_dtype = getattr(torch, \"float32\")\n\nbnbconfig = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model, \n    quantization_config=bnbconfig, \n    torch_dtype=compute_dtype, \n    low_cpu_mem_usage=True,\n    #trust_remote_code=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:18:53.858392Z","iopub.execute_input":"2025-01-08T21:18:53.858748Z","iopub.status.idle":"2025-01-08T21:20:19.780557Z","shell.execute_reply.started":"2025-01-08T21:18:53.858716Z","shell.execute_reply":"2025-01-08T21:20:19.779758Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from trl import setup_chat_format","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:19.781560Z","iopub.execute_input":"2025-01-08T21:20:19.781791Z","iopub.status.idle":"2025-01-08T21:20:19.789484Z","shell.execute_reply.started":"2025-01-08T21:20:19.781770Z","shell.execute_reply":"2025-01-08T21:20:19.788582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(base_model)\nmodel, tokenizer = setup_chat_format(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:19.791037Z","iopub.execute_input":"2025-01-08T21:20:19.791286Z","iopub.status.idle":"2025-01-08T21:20:20.612568Z","shell.execute_reply.started":"2025-01-08T21:20:19.791267Z","shell.execute_reply":"2025-01-08T21:20:20.610802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\ndata = load_dataset(dataset_path, split='all')\nprint(data)\n\ndata.to_csv('df.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:31.955375Z","iopub.execute_input":"2025-01-08T21:20:31.955693Z","iopub.status.idle":"2025-01-08T21:20:34.942826Z","shell.execute_reply.started":"2025-01-08T21:20:31.955663Z","shell.execute_reply":"2025-01-08T21:20:34.941986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('df.csv')\ndf.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:34.944135Z","iopub.execute_input":"2025-01-08T21:20:34.944468Z","iopub.status.idle":"2025-01-08T21:20:35.085888Z","shell.execute_reply.started":"2025-01-08T21:20:34.944444Z","shell.execute_reply":"2025-01-08T21:20:35.085138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\ndataset = load_dataset(dataset_path, split='all')\ndataset = dataset.shuffle(seed=42).select(range(2000)) \n\ndef format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"instruction\"]},\n               {\"role\": \"assistant\", \"content\": row[\"response\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row\n\ndataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)\n\ndataset['text'][3]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:38.495020Z","iopub.execute_input":"2025-01-08T21:20:38.495383Z","iopub.status.idle":"2025-01-08T21:20:40.157887Z","shell.execute_reply.started":"2025-01-08T21:20:38.495352Z","shell.execute_reply":"2025-01-08T21:20:40.157026Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nfrom peft import get_peft_model, prepare_model_for_kbit_training, PeftModel\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:42.478853Z","iopub.execute_input":"2025-01-08T21:20:42.479174Z","iopub.status.idle":"2025-01-08T21:20:43.166870Z","shell.execute_reply.started":"2025-01-08T21:20:42.479150Z","shell.execute_reply":"2025-01-08T21:20:43.165918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:47.606294Z","iopub.execute_input":"2025-01-08T21:20:47.606629Z","iopub.status.idle":"2025-01-08T21:20:47.619902Z","shell.execute_reply.started":"2025-01-08T21:20:47.606602Z","shell.execute_reply":"2025-01-08T21:20:47.619217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.add_special_tokens({'pad_token': '[PAD]'})\nmodel.resize_token_embeddings(len(tokenizer))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:20:50.040102Z","iopub.execute_input":"2025-01-08T21:20:50.040414Z","iopub.status.idle":"2025-01-08T21:21:15.204897Z","shell.execute_reply.started":"2025-01-08T21:20:50.040390Z","shell.execute_reply":"2025-01-08T21:21:15.204099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"finetuned_llama_for_telecom_chatbot\",\n    num_train_epochs=1,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=8,\n    optim=\"paged_adamw_32bit\",\n    save_steps=0,\n    logging_steps=25,\n    learning_rate=5e-4,\n    weight_decay=0.001,\n    fp16=True,\n    max_grad_norm=0.3,\n    warmup_ratio=0.03,\n    lr_scheduler_type=\"cosine\",\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:21:18.029578Z","iopub.execute_input":"2025-01-08T21:21:18.029862Z","iopub.status.idle":"2025-01-08T21:21:18.057997Z","shell.execute_reply.started":"2025-01-08T21:21:18.029840Z","shell.execute_reply":"2025-01-08T21:21:18.057150Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(\n        examples[\"text\"],\n        max_length=512,\n        truncation=True,\n        padding=\"max_length\"\n    )\n\n# Apply preprocessing to train and test datasets\ntokenized_train_dataset = dataset[\"train\"].map(preprocess_function, batched=True)\ntokenized_test_dataset = dataset[\"test\"].map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:21:20.436350Z","iopub.execute_input":"2025-01-08T21:21:20.436636Z","iopub.status.idle":"2025-01-08T21:21:21.284777Z","shell.execute_reply.started":"2025-01-08T21:21:20.436615Z","shell.execute_reply":"2025-01-08T21:21:21.283879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(tokenized_train_dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:21:23.508023Z","iopub.execute_input":"2025-01-08T21:21:23.508372Z","iopub.status.idle":"2025-01-08T21:21:23.512921Z","shell.execute_reply.started":"2025-01-08T21:21:23.508344Z","shell.execute_reply":"2025-01-08T21:21:23.511865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=tokenized_train_dataset,\n    eval_dataset=tokenized_test_dataset,\n    peft_config=peft_config,\n    tokenizer=tokenizer,\n    args=training_arguments,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:21:33.765724Z","iopub.execute_input":"2025-01-08T21:21:33.766019Z","iopub.status.idle":"2025-01-08T21:21:33.998577Z","shell.execute_reply.started":"2025-01-08T21:21:33.765996Z","shell.execute_reply":"2025-01-08T21:21:33.997915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T21:21:36.160639Z","iopub.execute_input":"2025-01-08T21:21:36.160931Z","iopub.status.idle":"2025-01-08T22:09:44.670201Z","shell.execute_reply.started":"2025-01-08T21:21:36.160910Z","shell.execute_reply":"2025-01-08T22:09:44.669341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['instruction'][11254]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:11:22.029636Z","iopub.execute_input":"2025-01-08T22:11:22.029922Z","iopub.status.idle":"2025-01-08T22:11:22.034933Z","shell.execute_reply.started":"2025-01-08T22:11:22.029899Z","shell.execute_reply":"2025-01-08T22:11:22.034251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"messages = [\n    {\n        \"role\": \"user\",\n        \"content\": \"Hi, please tell me about your payment methods\"\n    }\n]\n\nprompt = tokenizer.apply_chat_template(messages, tokenize=False, \n                                       add_generation_prompt=True)\n\ninputs = tokenizer(prompt, return_tensors='pt', padding=True, \n                   truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=150, \n                         num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nprint(text.split(\"assistant\")[1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:12:12.587130Z","iopub.execute_input":"2025-01-08T22:12:12.587429Z","iopub.status.idle":"2025-01-08T22:12:25.747126Z","shell.execute_reply.started":"2025-01-08T22:12:12.587407Z","shell.execute_reply":"2025-01-08T22:12:25.746289Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_model_name = \"finetuned_llama_for_telecom_chatbot\"\ntrainer.model.push_to_hub(new_model_name,  token=\"insert_your_hugging_face_token\", use_temp_dir = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T22:18:14.395816Z","iopub.execute_input":"2025-01-08T22:18:14.396146Z","iopub.status.idle":"2025-01-08T22:20:41.697951Z","shell.execute_reply.started":"2025-01-08T22:18:14.396118Z","shell.execute_reply":"2025-01-08T22:20:41.697190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}